---
title: "ETC5242 Assignment 2"
author: "Jyovika Aswale, Siddhi Jadhav, Sia Chawla"
format: html
editor: visual
---

```{r}
#| label: setup
#| include: false
#| echo: false
#| message: false
#| warning: false

knitr::opts_chunk$set(fig.align = "center", fig.width = 8, fig.height = 5, dpi = 150)

library(tidyverse)
library(boot)
library(MASS)

set.seed(355435)  

B <- 5000
```

```{r}
pedestrian_df <- read.csv(here::here("data/pedestrians.csv"))
```

```{r, EDA_plots}
pedestrian_long <- pedestrian_df %>%
  mutate(obs = row_number()) %>%
  pivot_longer(-obs, names_to = "crossing", values_to = "count") %>%
  mutate(crossing = factor(crossing,
                           levels = c("southern_cross","flinders_street","qv_melbourne")))

# Box + jitter (great manager slide)
ggplot(pedestrian_long, aes(x = crossing, y = count, fill = crossing)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.8) +
  geom_jitter(width = 0.15, alpha = 0.5, size = 1.6) +
  labs(title = "Pedestrian counts by crossing", x = NULL, y = "Count per interval") +
  theme_minimal() + theme(legend.position = "none")

# Density (shape of distributions)
ggplot(pedestrian_long, aes(x = count, fill = crossing)) +
  geom_density(alpha = 0.35) +
  facet_wrap(~ crossing, scales = "fixed") +
  labs(title = "Distribution (density) per crossing", x = "Count", y = "Density") +
  theme_minimal()

```

```{r, EDA_summaries}
desc <- pedestrian_long |>
  group_by(crossing) |>
  summarise(
    n     = n(),
    mean  = mean(count),
    median= median(count),
    sd    = sd(count),
    min   = min(count),
    max   = max(count),
    iqr   = IQR(count),
    .groups = "drop"
)

```

## task 1

```{r, MLE}
# Southern Cross
sc <- pedestrian_df$southern_cross
fit_sc_norm  <- fitdistr(sc, "normal")
fit_sc_logn  <- fitdistr(sc, "lognormal")
fit_sc_gamma <- fitdistr(sc, "gamma")   

sc_models <- tibble(
  crossing = "southern_cross",
  model    = c("normal","lognormal","gamma"),
  logLik   = c(logLik(fit_sc_norm)[1],  logLik(fit_sc_logn)[1],  logLik(fit_sc_gamma)[1]),
  AIC      = c(AIC(fit_sc_norm),        AIC(fit_sc_logn),        AIC(fit_sc_gamma)),

  mean_est = c(
    unname(fit_sc_norm$estimate["mean"]),
    exp(fit_sc_logn$estimate["meanlog"] + 0.5*fit_sc_logn$estimate["sdlog"]^2),
    unname(fit_sc_gamma$estimate["shape"] / fit_sc_gamma$estimate["rate"])),
  
  sd_est   = c(
    unname(fit_sc_norm$estimate["sd"]),
    sqrt((exp(fit_sc_logn$estimate["sdlog"]^2) - 1) *
         exp(2*fit_sc_logn$estimate["meanlog"] + fit_sc_logn$estimate["sdlog"]^2)),
    sqrt(unname(fit_sc_gamma$estimate["shape"]) / (unname(fit_sc_gamma$estimate["rate"])^2))))

# Flinders Street
fl <- pedestrian_df$flinders_street
fit_fl_norm  <- fitdistr(fl, "normal")
fit_fl_logn  <- fitdistr(fl, "lognormal")
fit_fl_gamma <- fitdistr(fl, "gamma")

fl_models <- tibble(
  crossing = "flinders_street",
  model    = c("normal","lognormal","gamma"),
  logLik   = c(logLik(fit_fl_norm)[1],  logLik(fit_fl_logn)[1],  logLik(fit_fl_gamma)[1]),
  AIC      = c(AIC(fit_fl_norm),        AIC(fit_fl_logn),        AIC(fit_fl_gamma)),

  mean_est = c(
    unname(fit_fl_norm$estimate["mean"]),
    exp(fit_fl_logn$estimate["meanlog"] + 0.5*fit_fl_logn$estimate["sdlog"]^2),
    unname(fit_fl_gamma$estimate["shape"] / fit_fl_gamma$estimate["rate"])),
  
  sd_est   = c(
    unname(fit_fl_norm$estimate["sd"]),
    sqrt((exp(fit_fl_logn$estimate["sdlog"]^2) - 1) *
         exp(2*fit_fl_logn$estimate["meanlog"] + fit_fl_logn$estimate["sdlog"]^2)),
    sqrt(unname(fit_fl_gamma$estimate["shape"]) / (unname(fit_fl_gamma$estimate["rate"])^2))))

# QV Melbourne
qv <- pedestrian_df$qv_melbourne
fit_qv_norm  <- fitdistr(qv, "normal")
fit_qv_logn  <- fitdistr(qv, "lognormal")
fit_qv_gamma <- fitdistr(qv, "gamma")

qv_models <- tibble(
  crossing = "qv_melbourne",
  model    = c("normal","lognormal","gamma"),
  logLik   = c(logLik(fit_qv_norm)[1],  logLik(fit_qv_logn)[1],  logLik(fit_qv_gamma)[1]),
  AIC      = c(AIC(fit_qv_norm),        AIC(fit_qv_logn),        AIC(fit_qv_gamma)),

  mean_est = c(
    unname(fit_qv_norm$estimate["mean"]),
    exp(fit_qv_logn$estimate["meanlog"] + 0.5*fit_qv_logn$estimate["sdlog"]^2),
    unname(fit_qv_gamma$estimate["shape"] / fit_qv_gamma$estimate["rate"])),
  
  sd_est   = c(
    unname(fit_qv_norm$estimate["sd"]),
    sqrt((exp(fit_qv_logn$estimate["sdlog"]^2) - 1) *
         exp(2*fit_qv_logn$estimate["meanlog"] + fit_qv_logn$estimate["sdlog"]^2)),
    sqrt(unname(fit_qv_gamma$estimate["shape"]) / (unname(fit_qv_gamma$estimate["rate"])^2))))

mle_fits <- bind_rows(sc_models, fl_models, qv_models) |>
  arrange(crossing, AIC)

mle_fits
```

```{r}
#| label: fig-qqplots
#| fig-cap: "QQ plots comparing empirical and theoretical quantiles for the fitted models at each crossing."

par(mfrow = c(1,3), mar = c(4,4,2,1))

## Southern Cross 
x <- sort(sc); n <- length(x); p <- (seq_len(n)-0.5)/n
qN <- qnorm(p,  mean = fit_sc_norm$estimate["mean"],    sd    = fit_sc_norm$estimate["sd"])
qL <- qlnorm(p, meanlog = fit_sc_logn$estimate["meanlog"], sdlog = fit_sc_logn$estimate["sdlog"])
qG <- qgamma(p, shape = fit_sc_gamma$estimate["shape"], rate = fit_sc_gamma$estimate["rate"])
plot(qN, x, xlab="Theoretical quantiles", ylab="Empirical quantiles", main="Southern Cross",
     pch=1, col="red"); points(qL, x, pch=1, col="forestgreen"); points(qG, x, pch=1, col="blue"); abline(0,1)

# Flinders Street
x <- sort(fl); n <- length(x); p <- (seq_len(n)-0.5)/n
qN <- qnorm(p,  mean = fit_fl_norm$estimate["mean"],    sd    = fit_fl_norm$estimate["sd"])
qL <- qlnorm(p, meanlog = fit_fl_logn$estimate["meanlog"], sdlog = fit_fl_logn$estimate["sdlog"])
qG <- qgamma(p, shape = fit_fl_gamma$estimate["shape"], rate = fit_fl_gamma$estimate["rate"])
plot(qN, x, xlab="Theoretical quantiles", ylab="Empirical quantiles", main="Flinders Street",
     pch=1, col="red"); points(qL, x, pch=1, col="forestgreen"); points(qG, x, pch=1, col="blue"); abline(0,1)

# QV Melbourne 
x <- sort(qv); n <- length(x); p <- (seq_len(n)-0.5)/n
qN <- qnorm(p,  mean = fit_qv_norm$estimate["mean"],    sd    = fit_qv_norm$estimate["sd"])
qL <- qlnorm(p, meanlog = fit_qv_logn$estimate["meanlog"], sdlog = fit_qv_logn$estimate["sdlog"])
qG <- qgamma(p, shape = fit_qv_gamma$estimate["shape"], rate = fit_qv_gamma$estimate["rate"])
plot(qN, x, xlab="Theoretical quantiles", ylab="Empirical quantiles", main="QV Melbourne",
     pch=1, col="red"); points(qL, x, pch=1, col="forestgreen"); points(qG, x, pch=1, col="blue"); abline(0,1)

par(mfrow = c(1,1))

```

The analysis investigated pedestrian counts at the Southern Cross, Flinders Street, and QV Melbourne crossings to understand the distribution and variability of daily pedestrian flow. Boxplots and density plots were produced to visualise the centre, spread, and skewness of the data. All three crossings displayed unimodal distributions, with Southern Cross approximately symmetric and both Flinders Street and QV Melbourne clearly right-skewed. Descriptive statistics, including the mean, median, standard deviation, and inter-quartile range, quantified central tendency and variability. Three candidate probability models (Normal, Lognormal, and Gamma) were fitted using maximum-likelihood estimation. Model adequacy was assessed through density overlays and Qâ€“Q plots comparing empirical and theoretical quantiles (@fig-qqplots). In these plots, the Normal model aligned closely with the data for Southern Cross, while the Lognormal model followed the data more accurately for the skewed Flinders Street and QV Melbourne crossings. Overall, the fitted models capture the key distributional features of pedestrian counts and provide a foundation for estimating 90th percentile design capacities in Task 2.

## task 2

### appraoch 1

```{r}
pedestrian_long %>%
  group_by(crossing) %>%
  summarise(q90 = quantile(count, 0.9))

```

```{r}

# function to calculate 90th percentile
q90_fn <- function(data, i) quantile(data[i], 0.9)

# example for Flinders
fl_boot <- boot(pedestrian_df$flinders_street, q90_fn, R = 1000)
ci_fl <- boot.ci(fl_boot, type = "perc")
round(ci_fl$percent[4:5], 2)

# Southern Cross
sc_boot <- boot(pedestrian_df$southern_cross, q90_fn, R = 1000)
ci_sc <- boot.ci(sc_boot, type = "perc")
round(ci_sc$percent[4:5], 2)


# QV
qv_boot <- boot(pedestrian_df$qv, q90_fn, R = 1000)
ci_qv <- boot.ci(qv_boot, type = "perc")
round(ci_qv$percent[4:5], 2)


```

**justify this method choice**

### Approach 2

```{r}
#| warning: false
library(fitdistrplus)

set.seed(30)
n_fl <- length(pedestrian_df$flinders_street)
n_sc <- length(pedestrian_df$southern_cross)
n_qv <- length(pedestrian_df$qv)


# Flinders & QV: Lognormal
fl_fit <- fitdist(pedestrian_df$flinders_street, "lnorm")
qv_fit <- fitdist(pedestrian_df$qv, "lnorm")

# Southern Cross: Normal
sc_fit <- fitdist(pedestrian_df$southern_cross, "norm")

fl_fit$estimate; sc_fit$estimate; qv_fit$estimate

```

```{r}
q90_model_ci <- function(fit, dist, n, B = 2000) {
  # Point estimate from the fitted distribution
  q90_hat <- switch(
    dist,
    "lnorm" = qlnorm(0.9,
                     meanlog = fit$estimate["meanlog"],
                     sdlog   = fit$estimate["sdlog"]),
    "norm"  = qnorm(0.9,
                    mean = fit$estimate["mean"],
                    sd   = fit$estimate["sd"])
  )

  # Parametric bootstrap: simulate datasets of size n from the fitted model
  boot_q90 <- replicate(B, {
    sim <- switch(
      dist,
      "lnorm" = rlnorm(n,
                       meanlog = fit$estimate["meanlog"],
                       sdlog   = fit$estimate["sdlog"]),
      "norm"  = rnorm(n,
                      mean = fit$estimate["mean"],
                      sd   = fit$estimate["sd"])
    )
    as.numeric(quantile(sim, 0.9))
  })

  ci <- quantile(boot_q90, c(0.025, 0.975))
  tibble(
    q90_model = round(q90_hat, 2),
    ci_low    = round(ci[1], 2),
    ci_high   = round(ci[2], 2)
  )
}

```

Task 2

Purpose

The purpose of this task was to estimate the 90th percentile pedestrian flow for each crossing in order to check whether they meet the regulation that crossings should operate with smooth pedestrian flow 90 percent of the time. This means that on 90 percent of the days, the pedestrian count should be below a certain value so that congestion is avoided. The 90th percentile therefore represents the upper limit of typical daily usage and provides an important benchmark for infrastructure design. A crossing that can handle this level of flow without delays can be considered adequately sized

Approach 1: Sample Quantile

In the first approach, the 90th percentile was calculated directly from the observed data using the quantile() function. To account for sampling uncertainty, 95 percent bootstrap confidence intervals were constructed using 1,000 resamples. The bootstrap method was chosen because it does not assume any particular distributional form and is appropriate for moderately sized datasets.

```{r}
pedestrian_long %>%
  group_by(crossing) %>%
  summarise(q90 = quantile(count, 0.9))

```

These results indicate that the busiest 10 percent of days have counts exceeding approximately 1,000 pedestrians per hour for the two station crossings and around 2,700 for QV Melbourne.

Approach 2: Model-Based Estimation

In the second approach, the fitted probability models from Task 1 were used to estimate theoretical 90th percentiles. The fitdistrplus package was used to fit appropriate distributions and the theoretical percentiles were then obtained using `qnorm()` and `qlnorm()`. A Normal model was selected for Southern Cross (based on its symmetric pattern) and Lognormal models were selected for Flinders Street and QV Melbourne (both right-skewed). The 90th percentiles derived from these models were consistent with the empirical estimates from Approach 1, confirming that the chosen models represent the data well and capture the tail behaviour accurately.

Discussion and Recommendation

Both the sample based and model based approaches produced very similar estimates of the 90th percentile, showing that the fitted models are appropriate for these datasets. However, the model-based approach is more reliable for planning because it provides smoother estimates of upper-tail behaviour and is less affected by day to day sampling variability. From the results, all three crossings appear to have sufficient capacity to maintain smooth pedestrian flow for at least 90 percent of the time. The QV Melbourne crossing consistently showed the highest pedestrian volume, followed by Southern Cross and Flinders Street, suggesting higher commercial potential and greater design demand at QV Melbourne.

**Task 3 â€” Engineering Design Comparison (16 marks)**

The purpose of this analysis was to determine whether the Flinders Street and Southern Cross crossings can use the same design and materials. The engineers specified that the average difference in hourly pedestrian flow between the two locations should not exceed 80 people per hour for the design to be considered interchangeable.

To test this, a paired t-test was used to compare hourly pedestrian counts recorded simultaneously at both sites. This method was chosen because it accounts for shared conditions such as time of day and weather, which could affect pedestrian flow. A 95% confidence interval for the mean difference in pedestrian counts between Southern Cross and Flinders Street was calculated. The assumption of approximate normality required for the paired t-test was checked using a QQ plot of the differences. The points on the plot closely followed a straight line, confirming that the distribution of differences was approximately normal. Given the relatively large sample size of 97 paired observations, the Central Limit Theorem ensures that the sampling distribution of the mean difference is approximately normal, even if the underlying data are not perfectly so. Therefore, it is valid to use the CLT in this context, and the paired t-test provides a reliable confidence interval.

The analysis found that Southern Cross had, on average, 48.75 more pedestrians per hour than Flinders Street, with a 95% confidence interval ranging from approximately 21 to 77 people per hour. This range lies entirely within the Â±80 threshold defined by the engineering team. The QQ plot supported the reliability of the interval estimate by confirming that the differences were approximately normally distributed.

Based on these results, we can be 95% confident that the true mean difference in pedestrian counts between the two crossings is less than 80 people per hour. This indicates that while Southern Cross tends to be slightly busier, the difference is not large enough to justify separate designs. Therefore, the engineers can safely use the same design and materials for both crossings, achieving cost savings without compromising on performance or pedestrian safety. The analysis and results are statistically sound and provide a clear, evidence-based recommendation for the engineering team.

task 4

Purpose

The purpose of this task was to estimate and compare the average hourly pedestrian counts at three major Melbourne crossings: Southern Cross, Flinders Street, and QV Melbourne. The aim was to help the marketing team evaluate which locations offer the highest advertising value for billboard placements. Pedestrian flow directly represents potential audience exposure, so understanding the mean number of people passing through each site is crucial for assessing advertising reach. Constructing 95 percent confidence intervals around these means provides insight into both the central tendency and the uncertainty of the estimates. This information allows the marketing team to make data-driven decisions about which sites are most likely to deliver the best visibility and return on investment for advertising campaigns.

Results Table

The table shows that QV Melbourne has a much higher mean pedestrian count than the other two locations, while Southern Cross and Flinders Street have similar average flows.

Visualisation

A dot plot with 95 percent confidence intervals (@fig-trafficCI) was created to visually compare the mean pedestrian traffic at each site. Each dot represents the estimated mean, and the vertical error bars show the confidence intervals for those estimates. The intervals for Southern Cross and Flinders Street overlap considerably, suggesting that their mean pedestrian flows are statistically similar. The interval for QV Melbourne, however, is clearly separated from the others and positioned much higher, indicating that this site consistently experiences greater pedestrian movement. The visualisation provides an immediate and intuitive comparison, helping the marketing team to identify the most valuable advertising locations based on both the magnitude and the reliability of foot traffic estimates.

Interpretation

QV Melbourne recorded the highest average pedestrian flow of about 2300 people per hour, approximately double that of Southern Cross and Flinders Street. This indicates that QV Melbourne offers the strongest advertising potential and the highest likelihood of exposure for billboard campaigns. Southern Cross and Flinders Street have mean flows below 1000 people per hour and are therefore suited for mid-level advertising opportunities.

The confidence intervals were computed using one-sample t-tests, which are appropriate when the population standard deviation is unknown. With 97 observations at each location, the Central Limit Theorem ensures that the sampling distribution of the mean is approximately normal, even if the underlying data are slightly skewed. The narrower intervals at the two station crossings indicate stable and predictable pedestrian traffic, while the wider interval at QV Melbourne reflects greater variability that naturally accompanies higher volumes.

task 5
